{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '3' 'male' '4' '3' '2' '27.9' 'S' '0.0' '0.0' '1.0' '0.0' '0.0' '0.0'\n",
      " '1.0']\n",
      "[ 0.   4.   3.   2.  27.9  0.   0.   1.   0.   0.   0.   1. ]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "with open('q3_test_dataset.csv','r') as csvfile:\n",
    "    dataset = list(csv.reader(csvfile))\n",
    "my_list = []\n",
    "for i in dataset:\n",
    "    my_list.append(i)\n",
    "\n",
    "with open('q3_train_dataset.csv','r') as csvfile:\n",
    "    dataset_train = list(csv.reader(csvfile))\n",
    "my_list_train = []\n",
    "for i in dataset_train:\n",
    "    my_list_train.append(i)\n",
    "\n",
    "#Adding dummy variable\n",
    "data_test = np.array(my_list)\n",
    "data_train = np.array(my_list_train)\n",
    "\n",
    "rec = []\n",
    "data_test = data_test[1:,:]\n",
    "data_train = data_train[1:,:]\n",
    "full = np.append(data_test,data_train,axis = 0)\n",
    "fulldata = np.zeros((data_train.shape[0] + data_test.shape[0],15)) #creating full data first 179 test last 712 train\n",
    "fulldata = fulldata.astype('str')\n",
    "c = 0\n",
    "for row in full:\n",
    "\n",
    "    if row[1] == '1':\n",
    "        rec = [1.0,0.0,0.0]\n",
    "    elif row[1] == '2':\n",
    "        rec = [0.0,1.0,0.0]\n",
    "    elif row[1] == '3':\n",
    "        rec = [0.0,0.0,1.0]\n",
    "\n",
    "    if row[2] == \"male\":\n",
    "        rec.append(0.0)\n",
    "    else:\n",
    "        rec.append(1.0)\n",
    "\n",
    "    if row[7] == \"C\":\n",
    "        rec.append(1.0)\n",
    "        rec.append(0.0)\n",
    "        rec.append(0.0)\n",
    "    elif row[7] == \"Q\":\n",
    "        rec.append(0.0)\n",
    "        rec.append(1.0)\n",
    "        rec.append(0.0)\n",
    "    elif row[7] == \"S\":\n",
    "        rec.append(0.0)\n",
    "        rec.append(0.0)\n",
    "        rec.append(1.0)\n",
    "    rec = np.array(rec)\n",
    "    fulldata[c] = np.append(full[c],rec)\n",
    "    rec = []\n",
    "    c = c + 1\n",
    "print(fulldata[0])\n",
    "fulldata = np.delete(fulldata,[1,2,7],axis = 1)\n",
    "fulldata = fulldata.astype('float64')\n",
    "print(fulldata[0])\n",
    "#normalizing colmns\n",
    "col_index = 0\n",
    "for col in fulldata.T:\n",
    "    fulldata[:,col_index] = (fulldata[:,col_index] - np.min(col)) / (np.max(col) - np.min(col))\n",
    "    col_index = col_index + 1\n",
    "x_test = fulldata[:179,1:]\n",
    "x_train = fulldata[179:,1:]\n",
    "y_test = fulldata[:179,0].reshape(179,1)\n",
    "y_train = fulldata[179:,0].reshape(712,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.random.normal(0,0.01,11).reshape(11,1)\n",
    "alpha = np.array([0.0001,0.001,0.1])\n",
    "    \n",
    "#full batch gradient descent\n",
    "def full_batch(x_train,y_train,x_test,alpha,max_iter):\n",
    "    beta = np.random.normal(0,0.01,11).reshape(11,1)\n",
    "    b0 = np.random.normal(0,0.01,1)\n",
    "    for i in range(max_iter):\n",
    "        z = x_train @ beta\n",
    "        z = z + b0\n",
    "        sigmz = 1 / (1 + np.exp(-z))\n",
    "        grad = ((y_train - sigmz).T @ x_train).reshape(11,1) \n",
    "        grad0 = np.sum(y_train - sigmz)\n",
    "\n",
    "        beta = beta + alpha*grad\n",
    "        b0 = b0 + alpha*grad0\n",
    "        if((i+1) % 100 == 0):\n",
    "            print(f'Model Weights in iteration {i+1} = {np.insert(beta,0, b0)}')\n",
    "            print()\n",
    "    \n",
    "    y_batch = b0 + x_test @ beta\n",
    "    y_batch = (y_batch >= 0).astype(int)\n",
    "    return y_batch\n",
    "\n",
    "# acc_batch = (y_batch == y_test).all(axis=1).mean()\n",
    "# print(acc_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastic gradient descent\n",
    "def stoch(x_train,y_train,x_test,alpha,max_iter):\n",
    "    beta_s = np.random.normal(0,0.01,11).reshape(11,1)\n",
    "    b0_s = np.random.normal(0,0.01,1)\n",
    "    for i in range(max_iter):\n",
    "        rand_ind = np.random.randint(712)\n",
    "        x_rand = x_train[rand_ind]\n",
    "        y_rand = y_train[rand_ind]\n",
    "        z = x_rand @ beta_s\n",
    "        z = z + b0_s\n",
    "        sigmz = 1 / (1 + np.exp(-z))\n",
    "        grad = ((y_rand - sigmz) * x_rand).reshape(11,1)\n",
    "        grad0 = y_rand - sigmz\n",
    "        beta_s = beta_s + alpha * grad\n",
    "        b0_s = b0_s + alpha * grad0\n",
    "    \n",
    "    y_s = b0_s + x_test @ beta_s\n",
    "    y_s = (y_s >= 0).astype(int)\n",
    "    return y_s\n",
    "\n",
    "# acc_s = (y_s == y_test).all(axis=1).mean()\n",
    "# print(acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini batch gradient descent\n",
    "def mini_batch(x_train,y_train,x_test,alpha,max_iter):\n",
    "    beta_32 = np.random.normal(0,0.01,11).reshape(11,1)\n",
    "    beta_32_0 = np.random.normal(0,0.01,1)\n",
    "    for i in range(max_iter):\n",
    "    \n",
    "        x_train_32 = x_train[i:i+32,:]\n",
    "        y_train_32 = y_train[i:i+32,:]\n",
    "        z = x_train_32 @ beta_32\n",
    "        z = z + beta_32_0\n",
    "        sigmz = 1 / (1 + np.exp(-z))\n",
    "        grad = ((y_train_32 - sigmz).T @ x_train_32).reshape(11,1)\n",
    "        grad0 = np.sum(y_train_32 - sigmz)\n",
    "        beta_32 = beta_32 + alpha*grad\n",
    "        beta_32_0 = beta_32_0 + alpha * grad0\n",
    "    \n",
    "    y_mini_batch = beta_32_0 + x_test @ beta_32\n",
    "    y_mini_batch = (y_mini_batch >= 0).astype(int) \n",
    "    return y_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf(y_predict, y_test):\n",
    "    \n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for i in range(y_predict.shape[0]):\n",
    "        if y_predict[i] == y_test[i]:\n",
    "            if(y_predict[i] == 1):\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if(y_predict[i] == 0):\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "                \n",
    "    conf_matrix = np.zeros((2,2))\n",
    "    conf_matrix[0,0] = TP\n",
    "    conf_matrix[0,1] = FP\n",
    "    conf_matrix[1,0] = FN\n",
    "    conf_matrix[1,1] = TN\n",
    "    \n",
    "    if(TP+FP+FN+TN == 0):\n",
    "        acc = 0\n",
    "    else:\n",
    "        acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "        \n",
    "    if(FP+TN == 0):\n",
    "        FPR = 0\n",
    "    else:    \n",
    "        FPR = FP/(FP+TN)\n",
    "         \n",
    "    if(TP+FP == 0):\n",
    "        prec = 0\n",
    "    else:        \n",
    "        prec =  TP/(TP+FP)\n",
    "             \n",
    "    if(TP+FN == 0):\n",
    "        recall = 0\n",
    "    else:    \n",
    "        recall = TP/(TP+FN)\n",
    "              \n",
    "    if(TN+FN == 0):\n",
    "        NPV = 0\n",
    "    else:   \n",
    "        NPV = TN/(TN+FN)\n",
    "            \n",
    "    if(FP+TP == 0):\n",
    "        FDR = 0\n",
    "    else:     \n",
    "        FDR = FP/(FP+TP)\n",
    "             \n",
    "    if(prec+recall == 0):\n",
    "        F1 = 0\n",
    "    else:    \n",
    "        F1 = (2*recall*prec)/(prec+recall)\n",
    "             \n",
    "    if(prec+recall == 0):\n",
    "        F2 = 0\n",
    "    else:    \n",
    "        F2 = (5*prec*recall)/(4*prec+recall)\n",
    "        \n",
    "    return conf_matrix,acc,FPR,prec,recall,NPV,FDR,F1,F2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix of 0.0001, learning rate Mini Batch:\n",
      "[[ 12.   0.]\n",
      " [ 57. 110.]]\n",
      " Accuracy:0.6815642458100558, FPR:0.0,Precision:1.0,Recall:0.17391304347826086,NPV:0.6586826347305389,FDR:0.0,F1:0.29629629629629634,F2:0.20833333333333334\n",
      "\n",
      " Confusion Matrix of 0.001, learning rate Mini Batch:\n",
      "[[ 35.   1.]\n",
      " [ 34. 109.]]\n",
      " Accuracy:0.8044692737430168, FPR:0.00909090909090909,Precision:0.9722222222222222,Recall:0.5072463768115942,NPV:0.7622377622377622,FDR:0.027777777777777776,F1:0.6666666666666666,F2:0.5608974358974359\n",
      "\n",
      " Confusion Matrix of 0.01, learning rate Mini Batch:\n",
      "[[ 45.   6.]\n",
      " [ 24. 104.]]\n",
      " Accuracy:0.8324022346368715, FPR:0.05454545454545454,Precision:0.8823529411764706,Recall:0.6521739130434783,NPV:0.8125,FDR:0.11764705882352941,F1:0.75,F2:0.6880733944954128\n",
      "\n",
      " Iteration time Mini Batch 0.0001: 0.042873382568359375, Iteration time Mini Batch 0.001: 0.021947622299194336,Iteration time Mini Batch 0.01: 0.017961740493774414\n"
     ]
    }
   ],
   "source": [
    "learningRate = np.array([0.0001,0.001,0.01])\n",
    "times = []\n",
    "#Mini batch calculations\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    y_mini_batch = mini_batch(x_train,y_train,x_test,learningRate[i],1000)\n",
    "    stop = time.time()\n",
    "    times.append(stop - start)\n",
    "    conf_matrix,acc,FPR,prec,recall,NPV,FDR,F1,F2 = get_conf(y_mini_batch,y_test)\n",
    "    print(f' Confusion Matrix of {learningRate[i]}, learning rate Mini Batch:\\n{conf_matrix}')\n",
    "    print(f' Accuracy:{acc}, FPR:{FPR},Precision:{prec},Recall:{recall},NPV:{NPV},FDR:{FDR},F1:{F1},F2:{F2}')\n",
    "    print()\n",
    "print(f' Iteration time Mini Batch 0.0001: {times[0]}, Iteration time Mini Batch 0.001: {times[1]},Iteration time Mini Batch 0.01: {times[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix of 0.0001, learning rate Stochastic GD:\n",
      "[[ 25.   6.]\n",
      " [ 44. 104.]]\n",
      " Accuracy:0.7206703910614525, FPR:0.05454545454545454,Precision:0.8064516129032258,Recall:0.36231884057971014,NPV:0.7027027027027027,FDR:0.1935483870967742,F1:0.5,F2:0.4071661237785017\n",
      "\n",
      " Confusion Matrix of 0.001, learning rate Stochastic GD:\n",
      "[[  0.   0.]\n",
      " [ 69. 110.]]\n",
      " Accuracy:0.6145251396648045, FPR:0.0,Precision:0,Recall:0.0,NPV:0.6145251396648045,FDR:0,F1:0,F2:0\n",
      "\n",
      " Confusion Matrix of 0.01, learning rate Stochastic GD:\n",
      "[[ 31.   4.]\n",
      " [ 38. 106.]]\n",
      " Accuracy:0.7653631284916201, FPR:0.03636363636363636,Precision:0.8857142857142857,Recall:0.4492753623188406,NPV:0.7361111111111112,FDR:0.11428571428571428,F1:0.5961538461538461,F2:0.4983922829581994\n",
      "\n",
      " Iteration time Stochastic 0.0001: 0.01695418357849121, Iteration time Stochastic 0.001: 0.014991044998168945,Iteration time Stochastic 0.01: 0.014927387237548828\n"
     ]
    }
   ],
   "source": [
    "learningRate = np.array([0.0001,0.001,0.01])\n",
    "times = []\n",
    "#Stochastic Gradient Ascent Calculations\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    y_stoch = stoch(x_train,y_train,x_test,learningRate[i],1000)\n",
    "    stop = time.time()\n",
    "    times.append(stop - start)\n",
    "    conf_matrix,acc,FPR,prec,recall,NPV,FDR,F1,F2 = get_conf(y_stoch,y_test)\n",
    "    print(f' Confusion Matrix of {learningRate[i]}, learning rate Stochastic GD:\\n{conf_matrix}')\n",
    "    print(f' Accuracy:{acc}, FPR:{FPR},Precision:{prec},Recall:{recall},NPV:{NPV},FDR:{FDR},F1:{F1},F2:{F2}')\n",
    "    print()\n",
    "print(f' Iteration time Stochastic 0.0001: {times[0]}, Iteration time Stochastic 0.001: {times[1]},Iteration time Stochastic 0.01: {times[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights in iteration 100 = [-0.24375706 -0.13923328 -0.02254757  0.03143011  0.05950121  0.24034707\n",
      "  0.04790939 -0.50180202  0.62504662  0.0791227  -0.01989099 -0.28803939]\n",
      "\n",
      "Model Weights in iteration 200 = [-0.29247748 -0.23072401 -0.03358422  0.0438601   0.09893254  0.38447158\n",
      "  0.07019412 -0.71693167  1.08705887  0.10838215 -0.02023675 -0.3656735 ]\n",
      "\n",
      "Model Weights in iteration 300 = [-0.33052324 -0.31874418 -0.04719663  0.04766288  0.12572671  0.46726396\n",
      "  0.0744861  -0.84206179  1.41264633  0.10993924 -0.01723236 -0.40828074]\n",
      "\n",
      "Model Weights in iteration 400 = [-0.35953758 -0.40171611 -0.06261278  0.04581045  0.14626847  0.52207716\n",
      "  0.07121033 -0.92261357  1.65049387  0.10181934 -0.0137413  -0.43266624]\n",
      "\n",
      "Model Weights in iteration 500 = [-0.38046706 -0.47946743 -0.0792648   0.04013403  0.16339998  0.56292263\n",
      "  0.06513224 -0.97831043  1.82854523  0.09105432 -0.01044824 -0.44612377]\n",
      "\n",
      "Model Weights in iteration 600 = [-0.39470503 -0.55253502 -0.09677717  0.03179046  0.17847295  0.59596898\n",
      "  0.05836866 -1.01883117  1.96409789  0.08040517 -0.0074065  -0.45275432]\n",
      "\n",
      "Model Weights in iteration 700 = [-0.40357471 -0.62158555 -0.11488675  0.02155496  0.19218821  0.62411227\n",
      "  0.05186712 -1.0493426   2.06859685  0.07090758 -0.00450234 -0.45503058]\n",
      "\n",
      "Model Weights in iteration 800 = [-4.08194379e-01 -6.87230684e-01 -1.33403300e-01  9.96781860e-03\n",
      "  2.04939232e-01  6.48809254e-01  4.60373528e-02 -1.07282949e+00\n",
      "  2.14995453e+00  6.28688493e-02 -1.60928655e-03 -4.54504565e-01]\n",
      "\n",
      "Model Weights in iteration 900 = [-4.09469766e-01 -7.49980981e-01 -1.52186849e-01 -2.58411237e-03\n",
      "  2.16964202e-01  6.70857698e-01  4.10331978e-02 -1.09114916e+00\n",
      "  2.21380903e+00  5.62881947e-02  1.36817371e-03 -4.52176758e-01]\n",
      "\n",
      "Model Weights in iteration 1000 = [-0.40812193 -0.81024651 -0.17113314 -0.01581827  0.22841783  0.69074306\n",
      "  0.03688412 -1.10553761  2.26426804  0.05104214  0.0044891  -0.4487038 ]\n",
      "\n",
      " Confusion Matrix of 0.0001, learning rate Full Batch GD:\n",
      "[[ 47.   9.]\n",
      " [ 22. 101.]]\n",
      " Accuracy:0.8268156424581006, FPR:0.08181818181818182,Precision:0.8392857142857143,Recall:0.6811594202898551,NPV:0.8211382113821138,FDR:0.16071428571428573,F1:0.752,F2:0.7078313253012049\n",
      "\n",
      "Model Weights in iteration 100 = [-0.39135513 -0.8345633  -0.14546625 -0.03571532  0.22699646  0.68626082\n",
      "  0.02668356 -1.11854061  2.27064149  0.04891177  0.00524792 -0.44941024]\n",
      "\n",
      "Model Weights in iteration 200 = [-0.3157184  -1.34221975 -0.337026   -0.17566631  0.32413786  0.81287017\n",
      "  0.01999043 -1.1628201   2.44862079  0.03939883  0.04374178 -0.40275441]\n",
      "\n",
      "Model Weights in iteration 300 = [-0.22230991 -1.74573541 -0.51349638 -0.3037229   0.40754528  0.88470268\n",
      "  0.03815207 -1.15940576  2.47592392  0.05370159  0.08508739 -0.3649943 ]\n",
      "\n",
      "Model Weights in iteration 400 = [-0.14159319 -2.07582784 -0.6726628  -0.41354536  0.4840868   0.93784965\n",
      "  0.05827486 -1.15195881  2.48663033  0.06902732  0.12107481 -0.33559073]\n",
      "\n",
      "Model Weights in iteration 500 = [-0.07479585 -2.3481233  -0.81576209 -0.50700528  0.55542677  0.98047004\n",
      "  0.075811   -1.14531799  2.49572318  0.08210533  0.15090249 -0.31169908]\n",
      "\n",
      "Model Weights in iteration 600 = [-0.01971462 -2.57394512 -0.94440036 -0.58654278  0.62232836  1.01525498\n",
      "  0.09051394 -1.13972464  2.50460062  0.09290135  0.17541069 -0.29192207]\n",
      "\n",
      "Model Weights in iteration 700 = [ 0.02584569 -2.76207162 -1.06010962 -0.65430859  0.68531248  1.04375396\n",
      "  0.10281431 -1.13496369  2.51311265  0.10178052  0.19557515 -0.2754054 ]\n",
      "\n",
      "Model Weights in iteration 800 = [ 0.06367618 -2.91942817 -1.16427606 -0.71210869  0.74478198  1.06712323\n",
      "  0.11315167 -1.13083982  2.52106099  0.10908479  0.21222756 -0.26153158]\n",
      "\n",
      "Model Weights in iteration 900 = [ 0.09519912 -3.05152704 -1.25813622 -0.76145213  0.80106076  1.08628336\n",
      "  0.12188594 -1.12721128  2.52834194  0.1150933   0.2260345  -0.24982409]\n",
      "\n",
      "Model Weights in iteration 1000 = [ 0.12154554 -3.16278717 -1.34278801 -0.80360379  0.85441482  1.10197829\n",
      "  0.12930303 -1.12397688  2.53492469  0.12003167  0.23752421 -0.23990575]\n",
      "\n",
      " Confusion Matrix of 0.001, learning rate Full Batch GD:\n",
      "[[ 47.   8.]\n",
      " [ 22. 102.]]\n",
      " Accuracy:0.8324022346368715, FPR:0.07272727272727272,Precision:0.8545454545454545,Recall:0.6811594202898551,NPV:0.8225806451612904,FDR:0.14545454545454545,F1:0.7580645161290324,F2:0.7099697885196374\n",
      "\n",
      "Model Weights in iteration 100 = [ 0.59435346 -3.45861386 -1.45281163 -0.92524611  0.93917384  1.43850596\n",
      "  0.30267666 -1.10935515  3.34222113  0.2147621   0.34357611  0.03678719]\n",
      "\n",
      "Model Weights in iteration 200 = [ 0.73421462 -4.14367838 -2.08613977 -1.23853818  1.38561416  1.50076973\n",
      "  0.34105695 -1.07013802  3.29825513  0.23714254  0.40688339  0.09096063]\n",
      "\n",
      "Model Weights in iteration 300 = [ 0.75632096 -4.2912219  -2.3412773  -1.30997675  1.67896975  1.49572163\n",
      "  0.35116464 -1.05309129  3.28549826  0.23669397  0.4175663   0.10283263]\n",
      "\n",
      "Model Weights in iteration 400 = [ 0.75624354 -4.32272433 -2.45271767 -1.3284021   1.87217513  1.48297558\n",
      "  0.35485444 -1.04411246  3.28079611  0.2331296   0.41844689  0.10543899]\n",
      "\n",
      "Model Weights in iteration 500 = [ 0.75277544 -4.3282406  -2.50537544 -1.33686967  1.99978199  1.47241034\n",
      "  0.35663439 -1.03879527  3.27856591  0.23008022  0.4175991   0.10586806]\n",
      "\n",
      "Model Weights in iteration 600 = [ 0.74959609 -4.32805895 -2.532016   -1.34326183  2.08450815  1.46485866\n",
      "  0.35766023 -1.03544877  3.27732473  0.22791983  0.41665017  0.10579803]\n",
      "\n",
      "Model Weights in iteration 700 = [ 0.74722627 -4.3268871  -2.54631074 -1.34850092  2.14106116  1.45967066\n",
      "  0.35830573 -1.0332761   3.27657287  0.22645846  0.41589638  0.10564337]\n",
      "\n",
      "Model Weights in iteration 800 = [ 0.74555998 -4.32578542 -2.55438228 -1.35260816  2.1789709   1.45614807\n",
      "  0.35872792 -1.03184199  3.27609671  0.2254801   0.41534856  0.10550326]\n",
      "\n",
      "Model Weights in iteration 900 = [ 0.7444124  -4.32493906 -2.55914307 -1.35567722  2.20446353  1.4537641\n",
      "  0.35900875 -1.03088642  3.27578758  0.22482517  0.41496368  0.1053955 ]\n",
      "\n",
      "Model Weights in iteration 1000 = [ 0.74362868 -4.32432986 -2.56205425 -1.35789349  2.22164436  1.45215177\n",
      "  0.35919703 -1.0302461   3.27558388  0.22438569  0.41469748  0.10531745]\n",
      "\n",
      " Confusion Matrix of 0.01, learning rate Full Batch GD:\n",
      "[[53. 20.]\n",
      " [16. 90.]]\n",
      " Accuracy:0.7988826815642458, FPR:0.18181818181818182,Precision:0.726027397260274,Recall:0.7681159420289855,NPV:0.8490566037735849,FDR:0.273972602739726,F1:0.7464788732394365,F2:0.7593123209169055\n",
      "\n",
      " Iteration time Full Batch GD 0.0001: 0.04587817192077637, Iteration time Full Batch GD 0.001: 0.03493857383728027,Iteration time Full Batch GD 0.01: 0.0359039306640625\n"
     ]
    }
   ],
   "source": [
    "learningRate = np.array([0.0001,0.001,0.01])\n",
    "times = []\n",
    "#Stochastic Gradient Ascent Calculations\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    y_full = full_batch(x_train,y_train,x_test,learningRate[i],1000)\n",
    "    stop = time.time()\n",
    "    times.append(stop - start)\n",
    "    conf_matrix,acc,FPR,prec,recall,NPV,FDR,F1,F2 = get_conf(y_full,y_test)\n",
    "    print(f' Confusion Matrix of {learningRate[i]}, learning rate Full Batch GA:\\n{conf_matrix}')\n",
    "    print(f' Accuracy:{acc}, FPR:{FPR},Precision:{prec},Recall:{recall},NPV:{NPV},FDR:{FDR},F1:{F1},F2:{F2}')\n",
    "    print()\n",
    "print(f' Iteration time Full Batch GA 0.0001: {times[0]}, Iteration time Full Batch GA 0.001: {times[1]},Iteration time Full Batch GA 0.01: {times[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights in iteration 100 = [ 0.60510926 -3.45934947 -1.4621866  -0.9237445   0.95014831  1.4250249\n",
      "  0.29025017 -1.12138751  3.3420412   0.21610901  0.3452407   0.0386037 ]\n",
      "\n",
      "Model Weights in iteration 200 = [ 0.74494531 -4.14386449 -2.09025607 -1.2379585   1.39240476  1.48759645\n",
      "  0.32855571 -1.08242856  3.29813368  0.238606    0.40852182  0.09266164]\n",
      "\n",
      "Model Weights in iteration 300 = [ 0.76709078 -4.29122108 -2.34324511 -1.30988706  1.68326416  1.48274737\n",
      "  0.33862601 -1.0655043   3.28542976  0.23823613  0.41919566  0.10450315]\n",
      "\n",
      "Model Weights in iteration 400 = [ 0.76705691 -4.32268192 -2.45370807 -1.32848693  1.87495253  1.47013154\n",
      "  0.3422961  -1.05659243  3.280756    0.23471828  0.42008123  0.10710156]\n",
      "\n",
      "Model Weights in iteration 500 = [ 0.76362276 -4.32819707 -2.50589668 -1.33699315  2.0016066   1.45965132\n",
      "  0.3440646  -1.05131487  3.27854142  0.23169673  0.41924101  0.10752918]\n",
      "\n",
      "Model Weights in iteration 600 = [ 0.76046768 -4.32802368 -2.53230267 -1.34337507  2.0857192   1.45215555\n",
      "  0.34508336 -1.04799293  3.27730929  0.22955351  0.41829873  0.1074596 ]\n",
      "\n",
      "Model Weights in iteration 700 = [ 0.75811472 -4.32686079 -2.54647526 -1.34859086  2.14187039  1.44700462\n",
      "  0.34572433 -1.04583592  3.27656293  0.22810303  0.41755003  0.10730582]\n",
      "\n",
      "Model Weights in iteration 800 = [ 0.75646002 -4.32576655 -2.55448043 -1.35267501  2.17951402  1.44350677\n",
      "  0.34614354 -1.044412    3.27609021  0.22713174  0.4170059   0.10716654]\n",
      "\n",
      "Model Weights in iteration 900 = [ 0.75532035 -4.32492582 -2.55920359 -1.35572514  2.20482912  1.44113938\n",
      "  0.34642241 -1.04346315  3.27578328  0.22648144  0.41662362  0.10705946]\n",
      "\n",
      "Model Weights in iteration 1000 = [ 0.75454202 -4.32432069 -2.56209256 -1.35792714  2.22189093  1.43953821\n",
      "  0.34660938 -1.04282729  3.27558101  0.22604504  0.41635922  0.10698192]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_stoch,beta,beta0 = full_batch(x_train,y_train,x_test,0.01,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.32432069]\n",
      " [-2.56209256]\n",
      " [-1.35792714]\n",
      " [ 2.22189093]\n",
      " [ 1.43953821]\n",
      " [ 0.34660938]\n",
      " [-1.04282729]\n",
      " [ 3.27558101]\n",
      " [ 0.22604504]\n",
      " [ 0.41635922]\n",
      " [ 0.10698192]]\n"
     ]
    }
   ],
   "source": [
    "print(beta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04498618, 0.375     , 0.33333333, 0.05445717, 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
